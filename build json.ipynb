{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#將id group  做成字典\n",
    "#step 1\n",
    "def put_id_group_in_dic(id_group_file_path):\n",
    "    with open(id_group_file_path, 'r') as f:\n",
    "        groupnum= f.read()\n",
    "    groupnum.split('\\n')\n",
    "    group_dic={}\n",
    "    for one_id_group in groupnum.split('\\n'):\n",
    "        one_patent_id=one_id_group.split(',')[0][1:]\n",
    "        one_patent_groupnum=one_id_group.split(',')[1][0:-1]\n",
    "        group_dic[one_patent_id]=one_patent_groupnum\n",
    "    print \"step 1 finish\"\n",
    "    return group_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#將該ID切出的字併入上面的字典\n",
    "#step 2\n",
    "def merge_keywords(id_keywords_file_path, group_dic):\n",
    "    word_list=[]\n",
    "    with open(id_keywords_file_path, 'r') as f:\n",
    "        all_patent= f.read()\n",
    "    f.close()\n",
    "    for one_patent in all_patent.split('\\n'):\n",
    "        one_patent_id=one_patent.split(\",\")[0].strip()\n",
    "        one_patent_keyword=one_patent.split(\",\")[1].strip()\n",
    "        for one_word in one_patent_keyword.split(\" \"):\n",
    "            word_list.append(one_word)\n",
    "        new_value =list(group_dic[one_patent_id]) + word_list\n",
    "        group_dic[one_patent_id]=new_value   \n",
    "    print \"step 2 finish\"\n",
    "    return group_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#合併寫法160篇  大約7秒\n",
    "#step 3\n",
    "def source_to_big_dic(source_dic):\n",
    "    big_dic={}\n",
    "    count=0\n",
    "    for _id in source_dic:  #一筆一筆抓_id\n",
    "        count+=1\n",
    "        print count\n",
    "        I_got_this = 0  #清除抓到旗標\n",
    "    #=======================================以下為判斷是否已有該群組之程式碼=====================================\n",
    "        for group_num in big_dic:    #將大字典中的當前群組抓出來\n",
    "            if source_dic[_id][0]==group_num:    #比對該群組是否等於該筆id所屬的群組\n",
    "                I_got_this = 1               #有抓到就豎起抓到旗標\n",
    "\n",
    "    #=====================================以下為入字庫程式碼==============================================\n",
    "                big_dic[source_dic[_id][0]][source_dic[_id][0]+\"_id\"].append(_id)\n",
    "                for one_words in source_dic[_id]:                #開始把該筆_ID內的關鍵字取出\n",
    "                    if one_words not in big_dic[group_num]:   #判斷是否已在該群組中出現   沒有就建新字\n",
    "                        big_dic[group_num][one_words] = 1      #建出目前判斷的字\n",
    "                    else: \n",
    "                        big_dic[group_num][one_words]=big_dic[group_num][one_words]+1  #更新該字詞之數量\n",
    "\n",
    "    #====================================以下違建立新群組程式碼=====並建立\"0~n\"_id之KEY========================     \n",
    "        if I_got_this == 0:         #判斷抓到旗標，若沒豎起表示沒抓到\n",
    "            big_dic[source_dic[_id][0]]={}     #在big_dic中建立新的key (新群組)\n",
    "            big_dic[source_dic[_id][0]][source_dic[_id][0]+\"_id\"]=[]    #在新建的群組中在建立一個\"0_id\"的list\n",
    "            group_num=source_dic[_id][0]       #將新群組之號碼設成要入之字庫\n",
    "\n",
    "    #=====================================以下為入字庫程式碼=============================================\n",
    "            big_dic[source_dic[_id][0]][source_dic[_id][0]+\"_id\"].append(_id)  \n",
    "            for one_words in source_dic[_id]:                #開始把該筆_ID內的關鍵字取出\n",
    "                if one_words not in big_dic[group_num]:   #判斷是否已在該群組中出現   沒有就建新字\n",
    "                    big_dic[group_num][one_words] = 1      #建出目前判斷的字\n",
    "                else: \n",
    "                    big_dic[group_num][one_words]=big_dic[group_num][one_words]+1  #更新該字詞之數量\n",
    "    print \"step 3 finish\",\"=\"*1\n",
    "    return big_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 finish\n",
      "step 2 finish\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "step 3 finish =\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "#main 1\n",
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch('10.120.30.17:9200')\n",
    "\n",
    "file_path='C:\\\\Users\\\\BigData\\\\Desktop\\\\groupnum.txt'\n",
    "group_dic=put_id_group_in_dic(file_path)\n",
    "id_keywords_file_path='C:\\\\Users\\\\BigData\\\\Desktop\\\\total_words.txt'\n",
    "source_dic=merge_keywords(id_keywords_file_path, group_dic)\n",
    "big_dic=source_to_big_dic(source_dic)\n",
    "\n",
    "count=0\n",
    "for gn in big_dic: \n",
    "    es_dic={\"group\":\"\",\"_id\":[],\"keywords\":[],\"count\":[]}\n",
    "    es_dic[\"group\"]=gn\n",
    "    for key in big_dic[gn]:\n",
    "        if type(big_dic[gn][key]) != type([]):\n",
    "            es_dic[\"keywords\"].append(key)\n",
    "            es_dic[\"count\"].append(big_dic[gn][key])\n",
    "        else:\n",
    "            es_dic[\"_id\"].append(big_dic[gn][key])\n",
    "    new=int(gn)                \n",
    "    res = es.index(index=\"test160\", doc_type='test', id=new, body=es_dic)\n",
    "    print count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
